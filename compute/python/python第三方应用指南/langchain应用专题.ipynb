{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用本地ollama 保留链式处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    " \n",
    "# 创建 PromptTemplate 模板定义\n",
    "# my_prompt = PromptTemplate.from_template(\"\"\"回答这个问题:{input}\"\"\")\n",
    "\n",
    "my_prompt = PromptTemplate.from_template([\n",
    "    (\"system\",\"你是世界级技术专家\"),\n",
    "    (\"user\",\"{input}\"),\n",
    "])\n",
    "\n",
    "# 创建 Ollama 实例\n",
    "# 确保 Ollama 服务正在运行，并且模型已经拉取到本地\n",
    "ollama = Ollama(\n",
    "    base_url='http://127.0.0.1:11434',  # 本地 Ollama 服务地址\n",
    "    model='qwen2:7b',  # 你要使用的模型名称\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "# 链式动作可调用api 调用数据库  爬虫 结果储存 等动作\n",
    "# 创建链式调用  模板定义->大模型处理->输出内容解析   \n",
    "chain = my_prompt | ollama | StrOutputParser()\n",
    "\n",
    "# 调用链式调用\n",
    "output = chain.invoke({\"input\": \"你是谁？20字以内回答\"})\n",
    "\n",
    "# 打印输出\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！我是一名世界级的技术专家。在回答你的问题之前，我想先澄清一下，“富有”这个词在不同的人和文化背景下有不同的定义。通常，它不仅仅意味着拥有大量的财富或资源，还可能包括健康、知识、人际关系等非物质的财富。\n",
      "\n",
      "### 如何变得“富有”\n",
      "\n",
      "1. **知识与技能积累**：成为某个领域的专家，无论是技术、艺术还是管理，都需要通过学习和实践不断积累专业知识和技能。这不仅能够提升个人的职业发展，也增加了创造财富的能力。\n",
      "\n",
      "2. **健康投资**：健康是无法替代的财富。保持良好的身体状况不仅可以提高生活质量和效率，还能够在长期职业生涯中保持高产出。定期进行体检、适当运动、合理饮食都是关键。\n",
      "\n",
      "3. **财务规划与管理**：\n",
      "   - 学习财务管理知识：了解如何投资、理财和储蓄，通过金融资产的增长来增加财富。\n",
      "   - 财务自由计划：设立短期和长期的财务目标，并制定实现这些目标的策略。这可能包括建立紧急基金、投资退休金账户等。\n",
      "\n",
      "4. **人际关系**：\n",
      "   - 与积极向上的人为伍：周围的人会影响你的思维模式和行为，选择有共同价值观和目标的朋友和同事。\n",
      "   - 建立广泛的社会网络：在工作和个人生活中拓展人脉，这不仅可以提供职业机会，还能给你带来宝贵的资源和建议。\n",
      "\n",
      "5. **创造力与创新**：\n",
      "   - 不断探索新领域：好奇心驱使的探索能激发新的想法和技术，可能为个人或团队创造经济价值。\n",
      "   - 持续学习和适应变化：技术和社会发展日新月异，保持学习的心态可以帮助你抓住机遇，应对挑战。\n",
      "\n",
      "6. **心理与情感健康**：\n",
      "   - 培养正面心态：乐观、感恩等积极态度可以提升生活质量，并在困难时期提供支持。\n",
      "   - 维护良好的人际关系：健康的社交关系不仅能带来快乐和支持，还能为你提供职业上的机会和建议。\n",
      "\n",
      "总之，“富有”不仅是物质财富的积累，更是一个综合了知识、健康、情感和社会资源的概念。通过持续学习、关注个人福祉和与他人建立联系，你可以以不同的方式实现“富有”。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.llms import Ollama\n",
    " \n",
    "# my_prompt = PromptTemplate.from_template(\"\"\"回答这个问题:{input}\"\"\")\n",
    "\n",
    "# 创建 PromptTemplate 模板定义\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"你是世界级技术专家\"),\n",
    "    (\"user\",\"{input}\"),\n",
    "]) \n",
    "\n",
    "# 创建 Ollama 实例\n",
    "# 确保 Ollama 服务正在运行，并且模型已经拉取到本地\n",
    "llm = Ollama(\n",
    "    base_url='http://127.0.0.1:11434',  # 本地 Ollama 服务地址\n",
    "    model='qwen2:7b',  # 你要使用的模型名称\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "# 链式动作可调用api 调用数据库  爬虫 结果储存 等动作\n",
    "# 创建链式调用  模板定义->大模型处理->输出内容解析   \n",
    "# chain = prompt | ollama \n",
    "chain = prompt | ollama | StrOutputParser()\n",
    "\n",
    "# 调用链式调用\n",
    "output = chain.invoke({\"input\": \"你好，你是谁？如何变得富有\"})\n",
    "\n",
    "# 打印输出\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个人工智能，名字叫bob', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好', additional_kwargs={}, response_metadata={}), AIMessage(content='我很好，谢谢', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "\n",
    "chat_template= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个人工智能，名字叫{name}\"),\n",
    "        (\"human\",\"你好\"),\n",
    "        (\"ai\",\"我很好，谢谢\"),\n",
    "        (\"human\",\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "messages = chat_template.format_messages(name=\"bob\",user_input=\"你好\") \n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个职业秘书{name}，可以润色内容', additional_kwargs={}, response_metadata={}), HumanMessage(content='你好，你是谁', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate ,HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage \n",
    "\n",
    "chat_template= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "        content=(\n",
    "            \"你是一个职业秘书{name}，可以润色内容\"\n",
    "        )),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\")\n",
    "      \n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"jack\",text=\"你好，你是谁\") \n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='你是一个秘书', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello!', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate ,MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage ,HumanMessage\n",
    "\n",
    "chat_template= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"你是一个秘书\"),\n",
    "        MessagesPlaceholder(\"msgs\")      \n",
    "    ]\n",
    ")\n",
    "\n",
    "# 修复后的代码\n",
    "messages = chat_template.invoke({\n",
    "    \"msgs\": [HumanMessage(content=\"hi!\"), HumanMessage(content=\"hello!\")]\n",
    "})\n",
    "print(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
